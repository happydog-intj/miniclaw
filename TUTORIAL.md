# ä»0åˆ°1å®ç°ä¸€ä¸ªæœ€ç®€å•çš„ MiniClaw - è¯¦ç»†æ•™ç¨‹

> **ç›®æ ‡**ï¼šç”¨ 400 è¡Œ Python ä»£ç ï¼Œä»é›¶å¼€å§‹æ„å»ºä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„ AI åŠ©æ‰‹

---

## ğŸ“‹ ç›®å½•

1. [è®¾è®¡ç†å¿µ](#1-è®¾è®¡ç†å¿µ)
2. [æ ¸å¿ƒæ¦‚å¿µ](#2-æ ¸å¿ƒæ¦‚å¿µ)
3. [é€æ­¥å®ç°](#3-é€æ­¥å®ç°)
4. [æµ‹è¯•è¿è¡Œ](#4-æµ‹è¯•è¿è¡Œ)
5. [æ‰©å±•åŠŸèƒ½](#5-æ‰©å±•åŠŸèƒ½)
6. [å¸¸è§é—®é¢˜](#6-å¸¸è§é—®é¢˜)

---

## 1. è®¾è®¡ç†å¿µ

### ğŸ¯ æ ¸å¿ƒåŸåˆ™

**æç®€ä¸»ä¹‰ (Minimalism)**
- å»æ‰æ‰€æœ‰ä¸å¿…è¦çš„æŠ½è±¡å±‚
- æ¯ä¸ªæ–‡ä»¶èŒè´£å•ä¸€æ¸…æ™°
- ä»£ç å³æ–‡æ¡£ï¼Œä¸€çœ‹å°±æ‡‚

**å®ç”¨ä¸»ä¹‰ (Pragmatism)**
- ä¼˜å…ˆå®ç°æ ¸å¿ƒåŠŸèƒ½
- ä½¿ç”¨æˆç†Ÿçš„ç¬¬ä¸‰æ–¹åº“
- é¿å…è¿‡æ—©ä¼˜åŒ–

### ğŸ“Š ä¸å®Œæ•´ MiniClaw çš„å¯¹æ¯”

```
å®Œæ•´ç‰ˆ MiniClaw (430,000+ è¡Œ):
â”œâ”€â”€ å¤æ‚çš„äº‹ä»¶æ€»çº¿ç³»ç»Ÿ
â”œâ”€â”€ æ’ä»¶åŒ–æ¶æ„
â”œâ”€â”€ å¤šç§ Channel æŠ½è±¡
â”œâ”€â”€ æµè§ˆå™¨è‡ªåŠ¨åŒ–
â”œâ”€â”€ å­ä»£ç†ç³»ç»Ÿ
â”œâ”€â”€ å¤æ‚çš„é…ç½®ç®¡ç†
â””â”€â”€ ... æ›´å¤šä¼ä¸šçº§ç‰¹æ€§

MiniClaw (400 è¡Œ):
â”œâ”€â”€ ç®€å•çš„æ¶ˆæ¯è·¯ç”±
â”œâ”€â”€ ç›´æ¥çš„å·¥å…·è°ƒç”¨
â”œâ”€â”€ å•ä¸€ Telegram é›†æˆ
â””â”€â”€ æ ¸å¿ƒ Agent é€»è¾‘
```

**æˆ‘ä»¬ä¿ç•™äº†ä»€ä¹ˆï¼Ÿ**
- âœ… LLM å·¥å…·è°ƒç”¨ï¼ˆFunction Callingï¼‰
- âœ… è¿­ä»£å¼å¤„ç†ï¼ˆReAct æ¨¡å¼ï¼‰
- âœ… ä¼šè¯ç®¡ç†
- âœ… æ–‡ä»¶å’Œå‘½ä»¤æ‰§è¡Œ

**æˆ‘ä»¬ç®€åŒ–äº†ä»€ä¹ˆï¼Ÿ**
- âŒ å¤æ‚çš„äº‹ä»¶æ€»çº¿ â†’ ç®€å•çš„ async å‡½æ•°
- âŒ å·¥å…·æ³¨å†Œè¡¨ â†’ if-else åŒ¹é…
- âŒ å¤šæ¸ é“æŠ½è±¡ â†’ åªæ”¯æŒ Telegram
- âŒ æ’ä»¶ç³»ç»Ÿ â†’ ç›´æ¥ä¿®æ”¹ä»£ç 

---

## 2. æ ¸å¿ƒæ¦‚å¿µ

### 2.1 ä»€ä¹ˆæ˜¯ Function Callingï¼Ÿ

**ä¼ ç»Ÿæ–¹å¼ï¼š**
```
ç”¨æˆ·: "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"
LLM: "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•è·å–å®æ—¶å¤©æ°”ä¿¡æ¯ã€‚"
```

**æœ‰ Function Callingï¼š**
```
ç”¨æˆ·: "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"
LLM: [è°ƒç”¨å·¥å…·] get_weather(location="current")
å·¥å…·: è¿”å› "æ™´å¤©ï¼Œ25Â°C"
LLM: "ä»Šå¤©æ˜¯æ™´å¤©ï¼Œæ°”æ¸© 25Â°C"
```

**æ ¸å¿ƒæœºåˆ¶ï¼š**

1. **å®šä¹‰å·¥å…·** (Tool Definition)
```python
{
    "name": "get_weather",
    "description": "è·å–å¤©æ°”ä¿¡æ¯",
    "parameters": {
        "location": {"type": "string"}
    }
}
```

2. **LLM å†³ç­–**
```
LLM åˆ†æç”¨æˆ·é—®é¢˜ â†’ åˆ¤æ–­éœ€è¦å“ªä¸ªå·¥å…· â†’ ç”Ÿæˆå·¥å…·è°ƒç”¨
```

3. **æ‰§è¡Œå·¥å…·**
```python
result = execute_tool("get_weather", {"location": "Beijing"})
```

4. **è¿”å›ç»“æœ**
```python
messages.append({
    "role": "tool",
    "content": result
})
# å†æ¬¡è°ƒç”¨ LLMï¼Œè®©å®ƒæ€»ç»“ç»“æœ
```

### 2.2 è¿­ä»£å¼å·¥å…·è°ƒç”¨ï¼ˆReAct æ¨¡å¼ï¼‰

**ä¸ºä»€ä¹ˆéœ€è¦å¤šè½®ï¼Ÿ**

å‡è®¾ç”¨æˆ·é—®ï¼š"åˆ†æ data.csv å¹¶ç”ŸæˆæŠ¥å‘Š"

```
ç¬¬1è½®:
LLM â†’ éœ€è¦å…ˆè¯»å–æ–‡ä»¶
å·¥å…· â†’ list_dir() æŸ¥çœ‹æœ‰å“ªäº›æ–‡ä»¶

ç¬¬2è½®:
LLM â†’ æ‰¾åˆ°äº† data.csvï¼Œè¯»å–å®ƒ
å·¥å…· â†’ read_file("data.csv")

ç¬¬3è½®:
LLM â†’ åˆ†ææ•°æ®...
å·¥å…· â†’ write_file("report.txt", "...")

ç¬¬4è½®:
LLM â†’ "âœ… å·²ç”ŸæˆæŠ¥å‘Š report.txt"
```

**è¿™å°±æ˜¯ ReAct (Reasoning + Acting)**ï¼š
- **Reasoning**: LLM æ€è€ƒä¸‹ä¸€æ­¥
- **Acting**: è°ƒç”¨å·¥å…·æ‰§è¡Œ
- **å¾ªç¯**: ç›´åˆ°ä»»åŠ¡å®Œæˆ

### 2.3 ä¼šè¯ç®¡ç†

**ä¸ºä»€ä¹ˆéœ€è¦ï¼Ÿ**

```
ç”¨æˆ·A: "æˆ‘å«å¼ ä¸‰"
Bot: "ä½ å¥½å¼ ä¸‰ï¼"
[è¿‡äº†ä¸€ä¼šå„¿...]
ç”¨æˆ·A: "æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ"
Bot: "ä½ å«å¼ ä¸‰"  â† éœ€è¦è®°ä½å†å²
```

**å®ç°æ–¹å¼ï¼š**

```python
# sessions/123456.json
[
    {"role": "user", "content": "æˆ‘å«å¼ ä¸‰"},
    {"role": "assistant", "content": "ä½ å¥½å¼ ä¸‰ï¼"},
    {"role": "user", "content": "æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ"},
    {"role": "assistant", "content": "ä½ å«å¼ ä¸‰"}
]
```

æ¯ä¸ªç”¨æˆ·ï¼ˆchat_idï¼‰ç‹¬ç«‹çš„å†å²è®°å½•ã€‚

---

## 3. é€æ­¥å®ç°

### Step 1: é…ç½®ç®¡ç† (config.py)

**èŒè´£ï¼š**
- åŠ è½½ç¯å¢ƒå˜é‡
- éªŒè¯å¿…è¦çš„é…ç½®
- åˆ›å»ºå·¥ä½œç›®å½•

```python
import os
from pathlib import Path

# ä»ç¯å¢ƒå˜é‡è¯»å–
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ç›®å½•ç»“æ„
WORKSPACE = Path("./workspace")
SESSION_DIR = Path("./sessions")

# éªŒè¯
if not TELEGRAM_TOKEN:
    raise ValueError("ç¼ºå°‘ TELEGRAM_TOKEN")
```

**ä¸ºä»€ä¹ˆåˆ†ç¦»é…ç½®ï¼Ÿ**
- å®‰å…¨ï¼šæ•æ„Ÿä¿¡æ¯ä¸ç¡¬ç¼–ç 
- çµæ´»ï¼šåˆ‡æ¢ç¯å¢ƒæ— éœ€æ”¹ä»£ç 
- æ¸…æ™°ï¼šæ‰€æœ‰é…ç½®é›†ä¸­ç®¡ç†

---

### Step 2: Agent æ ¸å¿ƒ (agent.py)

#### 2.1 åˆå§‹åŒ–

```python
class Agent:
    def __init__(self, model, workspace):
        self.model = model
        self.workspace = workspace
        self.max_iterations = 10
```

#### 2.2 ä¸»å¤„ç†æµç¨‹

```python
async def process(self, user_message, history):
    # 1. æ„å»º messages
    messages = [
        {"role": "system", "content": system_prompt},
        *history,
        {"role": "user", "content": user_message}
    ]
    
    # 2. è¿­ä»£å¾ªç¯
    for i in range(max_iterations):
        # è°ƒç”¨ LLM
        response = await acompletion(
            model=self.model,
            messages=messages,
            tools=self._get_tools()
        )
        
        # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç»“æŸ
        if not response.tool_calls:
            return response.content
        
        # æ‰§è¡Œå·¥å…·
        for tool_call in response.tool_calls:
            result = self._execute_tool(
                tool_call.function.name,
                tool_call.function.arguments
            )
            messages.append(tool_result)
    
    return "è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°"
```

#### 2.3 å·¥å…·å®šä¹‰

```python
def _get_tools(self):
    return [
        {
            "type": "function",
            "function": {
                "name": "read_file",
                "description": "è¯»å–æ–‡ä»¶å†…å®¹",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "path": {"type": "string"}
                    }
                }
            }
        },
        # ... å…¶ä»–å·¥å…·
    ]
```

#### 2.4 å·¥å…·æ‰§è¡Œ

```python
def _execute_tool(self, name, args):
    if name == "read_file":
        path = self.workspace / args["path"]
        return path.read_text()
    
    elif name == "write_file":
        path = self.workspace / args["path"]
        path.write_text(args["content"])
        return f"å·²å†™å…¥ {path}"
    
    elif name == "exec_shell":
        result = subprocess.run(
            args["command"],
            shell=True,
            capture_output=True
        )
        return result.stdout
```

**å…³é”®ç‚¹ï¼š**
- æ‰€æœ‰æ–‡ä»¶æ“ä½œåœ¨ workspace å†…
- Shell å‘½ä»¤éœ€è¦å®‰å…¨æ£€æŸ¥
- è¿”å›å­—ç¬¦ä¸²ç»“æœ

---

### Step 3: Telegram Bot (bot.py)

#### 3.1 ä¼šè¯ç®¡ç†

```python
def _load_history(chat_id):
    file = SESSION_DIR / f"{chat_id}.json"
    if file.exists():
        return json.loads(file.read_text())
    return []

def _save_history(chat_id, history):
    file = SESSION_DIR / f"{chat_id}.json"
    file.write_text(json.dumps(history, indent=2))
```

#### 3.2 æ¶ˆæ¯å¤„ç†

```python
async def handle_message(update, context):
    chat_id = update.effective_chat.id
    user_text = update.message.text
    
    # 1. åŠ è½½å†å²
    history = load_history(chat_id)
    
    # 2. è°ƒç”¨ agent
    agent = Agent(model=LLM_MODEL, workspace=WORKSPACE)
    response = await agent.process(user_text, history)
    
    # 3. ä¿å­˜å†å²
    history.append({"role": "user", "content": user_text})
    history.append({"role": "assistant", "content": response})
    save_history(chat_id, history)
    
    # 4. å‘é€å“åº”
    await update.message.reply_text(response)
```

#### 3.3 å¯åŠ¨ Bot

```python
def main():
    app = Application.builder().token(TELEGRAM_TOKEN).build()
    app.add_handler(MessageHandler(filters.TEXT, handle_message))
    app.run_polling()
```

---

## 4. æµ‹è¯•è¿è¡Œ

### 4.1 ç¯å¢ƒå‡†å¤‡

```bash
# 1. åˆ›å»ºé¡¹ç›®ç›®å½•
mkdir miniclaw && cd miniclaw

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate

# 3. å®‰è£…ä¾èµ–
pip install python-telegram-bot litellm loguru python-dotenv
```

### 4.2 é…ç½®

åˆ›å»º `.env` æ–‡ä»¶ï¼š
```env
TELEGRAM_TOKEN=ä½ çš„_Bot_Token
OPENAI_API_KEY=ä½ çš„_API_Key
LLM_MODEL=gpt-4o-mini
```

### 4.3 å¯åŠ¨

```bash
python bot.py
```

### 4.4 æµ‹è¯•åœºæ™¯

**åœºæ™¯1ï¼šåŸºæœ¬å¯¹è¯**
```
ä½ : ä½ å¥½
Bot: ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ
```

**åœºæ™¯2ï¼šæ–‡ä»¶æ“ä½œ**
```
ä½ : åˆ›å»ºä¸€ä¸ª hello.txt æ–‡ä»¶ï¼Œå†…å®¹æ˜¯ "Hello World"
Bot: [è°ƒç”¨ write_file]
     âœ… å·²å†™å…¥æ–‡ä»¶ï¼šhello.txt
```

**åœºæ™¯3ï¼šè¯»å–æ–‡ä»¶**
```
ä½ : è¯»å– hello.txt çš„å†…å®¹
Bot: [è°ƒç”¨ read_file]
     æ–‡ä»¶å†…å®¹ï¼šHello World
```

**åœºæ™¯4ï¼šæ‰§è¡Œå‘½ä»¤**
```
ä½ : åˆ—å‡ºå½“å‰ç›®å½•çš„æ‰€æœ‰æ–‡ä»¶
Bot: [è°ƒç”¨ list_dir]
     ç›®å½•å†…å®¹ï¼š
     ğŸ“„ hello.txt
```

**åœºæ™¯5ï¼šå¤šæ­¥éª¤ä»»åŠ¡**
```
ä½ : åˆ›å»ºä¸€ä¸ª Python è„šæœ¬ï¼Œæ‰“å° 1 åˆ° 10 çš„å¹³æ–¹ï¼Œç„¶åæ‰§è¡Œå®ƒ
Bot: 
[ç¬¬1è½®] è°ƒç”¨ write_file åˆ›å»º squares.py
[ç¬¬2è½®] è°ƒç”¨ exec_shell æ‰§è¡Œ python squares.py
ç»“æœï¼š
1
4
9
16
25
36
49
64
81
100
```

---

## 5. æ‰©å±•åŠŸèƒ½

### 5.1 æ·»åŠ ç½‘ç»œæœç´¢

```python
# åœ¨ agent.py çš„ _get_tools() ä¸­æ·»åŠ 
{
    "type": "function",
    "function": {
        "name": "web_search",
        "description": "æœç´¢ç½‘ç»œä¿¡æ¯",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {"type": "string", "description": "æœç´¢å…³é”®è¯"}
            }
        }
    }
}

# åœ¨ _execute_tool() ä¸­å¤„ç†
elif name == "web_search":
    import requests
    api_key = os.getenv("BRAVE_API_KEY")
    response = requests.get(
        "https://api.search.brave.com/res/v1/web/search",
        headers={"X-Subscription-Token": api_key},
        params={"q": args["query"]}
    )
    results = response.json()
    # æå–å‰ 3 æ¡ç»“æœ
    top_results = results["web"]["results"][:3]
    return "\n\n".join([
        f"{r['title']}\n{r['description']}\n{r['url']}"
        for r in top_results
    ])
```

### 5.2 æ·»åŠ å›¾ç‰‡ç†è§£

```python
# åœ¨ bot.py çš„ handle_message ä¸­
if update.message.photo:
    # ä¸‹è½½å›¾ç‰‡
    photo = update.message.photo[-1]
    file = await context.bot.get_file(photo.file_id)
    image_bytes = await file.download_as_bytearray()
    
    # è½¬æ¢ä¸º base64
    import base64
    image_b64 = base64.b64encode(image_bytes).decode()
    
    # æ„å»ºåŒ…å«å›¾ç‰‡çš„ message
    messages.append({
        "role": "user",
        "content": [
            {"type": "text", "text": caption or "åˆ†æè¿™å¼ å›¾ç‰‡"},
            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_b64}"}}
        ]
    })
```

### 5.3 æ·»åŠ æµå¼è¾“å‡º

```python
# åœ¨ agent.py ä¸­ä¿®æ”¹ acompletion è°ƒç”¨
response = await acompletion(
    model=self.model,
    messages=messages,
    tools=tools,
    stream=True  # å¯ç”¨æµå¼
)

# å¤„ç†æµå¼å“åº”
collected_text = ""
async for chunk in response:
    if chunk.choices[0].delta.content:
        collected_text += chunk.choices[0].delta.content
        # å®æ—¶æ›´æ–° Telegram æ¶ˆæ¯
        await update.message.edit_text(collected_text)
```

### 5.4 æ·»åŠ è®°å¿†ç³»ç»Ÿ

```python
# åœ¨ workspace/ ä¸­åˆ›å»º MEMORY.md
def _get_system_prompt(self):
    memory_file = self.workspace / "MEMORY.md"
    memory_content = ""
    if memory_file.exists():
        memory_content = f"\n\né•¿æœŸè®°å¿†ï¼š\n{memory_file.read_text()}"
    
    return f"""ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹...{memory_content}"""

# æ·»åŠ è®°å¿†å·¥å…·
{
    "name": "update_memory",
    "description": "æ›´æ–°é•¿æœŸè®°å¿†",
    "parameters": {
        "content": {"type": "string"}
    }
}
```

---

## 6. å¸¸è§é—®é¢˜

### Q1: LiteLLM æ˜¯ä»€ä¹ˆï¼Ÿ

**A:** LiteLLM æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„ LLM API å°è£…åº“ï¼Œæ”¯æŒï¼š
- OpenAI (GPT-4, GPT-3.5)
- Anthropic (Claude)
- Google (Gemini)
- Azure OpenAI
- å¼€æºæ¨¡å‹ (Ollama, vLLM)

**åˆ‡æ¢æ¨¡å‹åªéœ€æ”¹é…ç½®ï¼š**
```python
# OpenAI
model = "gpt-4o-mini"

# Claude
model = "claude-3-5-sonnet-20241022"

# æœ¬åœ° Ollama
model = "ollama/llama3.2"
```

### Q2: å†å²è®°å½•ä¼šçˆ†ç‚¸å—ï¼Ÿ

**A:** ä¼šï¼å»ºè®®é™åˆ¶é•¿åº¦ï¼š

```python
MAX_HISTORY_MESSAGES = 20

def _load_history(chat_id):
    history = json.loads(...)
    # åªä¿ç•™æœ€è¿‘ 20 æ¡
    return history[-MAX_HISTORY_MESSAGES:]
```

æˆ–ä½¿ç”¨æ»‘åŠ¨çª—å£ï¼š
```python
# ä¿ç•™æœ€è¿‘çš„ç”¨æˆ·æ¶ˆæ¯ + åŠ©æ‰‹å›å¤
user_messages = [m for m in history if m["role"] == "user"][-10:]
assistant_messages = [m for m in history if m["role"] == "assistant"][-10:]
```

### Q3: Token æ¶ˆè€—å¦‚ä½•ä¼˜åŒ–ï¼Ÿ

**A:** å‡ ä¸ªæŠ€å·§ï¼š

1. **å‹ç¼©å†å²**
```python
# ä½¿ç”¨æ‘˜è¦æ›¿ä»£å®Œæ•´å†å²
if len(history) > 10:
    summary = await summarize(history[:5])
    history = [
        {"role": "system", "content": f"ä¹‹å‰çš„å¯¹è¯æ‘˜è¦ï¼š{summary}"},
        *history[5:]
    ]
```

2. **å·¥å…·ç»“æœæˆªæ–­**
```python
if len(result) > 2000:
    result = result[:2000] + "\n... (å·²æˆªæ–­)"
```

3. **ä½¿ç”¨æ›´å°çš„æ¨¡å‹**
```python
# ç®€å•å¯¹è¯ç”¨ gpt-4o-mini
# å¤æ‚ä»»åŠ¡ç”¨ gpt-4o
```

### Q4: å¦‚ä½•è°ƒè¯•ï¼Ÿ

**A:** ä½¿ç”¨ loguru æ‰“å°è¯¦ç»†æ—¥å¿—ï¼š

```python
from loguru import logger

logger.debug(f"Messages: {messages}")
logger.info(f"Tool call: {tool_name}({args})")
logger.error(f"Error: {e}")
```

æŸ¥çœ‹ `sessions/` ç›®å½•çš„ JSON æ–‡ä»¶ï¼Œäº†è§£å¯¹è¯å†å²ã€‚

### Q5: éƒ¨ç½²åˆ°æœåŠ¡å™¨ï¼Ÿ

**A:** ä½¿ç”¨ systemd serviceï¼š

```ini
# /etc/systemd/system/miniclaw.service
[Unit]
Description=MiniClaw Bot
After=network.target

[Service]
Type=simple
User=ubuntu
WorkingDirectory=/home/ubuntu/miniclaw
Environment="PATH=/home/ubuntu/miniclaw/venv/bin"
ExecStart=/home/ubuntu/miniclaw/venv/bin/python bot.py
Restart=always

[Install]
WantedBy=multi-user.target
```

å¯åŠ¨ï¼š
```bash
sudo systemctl enable miniclaw
sudo systemctl start miniclaw
sudo systemctl status miniclaw
```

---

## ğŸ“ æ€»ç»“

### ä½ å­¦åˆ°äº†ä»€ä¹ˆ

1. **LLM Function Calling** çš„åŸç†å’Œå®ç°
2. **è¿­ä»£å¼å·¥å…·è°ƒç”¨**ï¼ˆReAct æ¨¡å¼ï¼‰
3. **ä¼šè¯ç®¡ç†**çš„ç®€å•æœ‰æ•ˆæ–¹æ¡ˆ
4. **Telegram Bot** çš„åŸºæœ¬ä½¿ç”¨
5. **æç®€æ¶æ„**çš„è®¾è®¡æ€æƒ³

### ä¸‹ä¸€æ­¥

- ğŸ”§ **å®è·µ**ï¼šè¿è¡Œä»£ç ï¼Œä½“éªŒå·¥å…·è°ƒç”¨
- ğŸ“ **æ‰©å±•**ï¼šæ·»åŠ ä½ éœ€è¦çš„åŠŸèƒ½ï¼ˆæœç´¢ã€å›¾ç‰‡ã€å®šæ—¶ä»»åŠ¡ï¼‰
- ğŸ›¡ï¸ **åŠ å›º**ï¼šæ”¹è¿›å®‰å…¨æ€§ï¼ˆç™½åå•ã€æ²™ç®±ï¼‰
- ğŸš€ **éƒ¨ç½²**ï¼šä¸Šçº¿åˆ°æœåŠ¡å™¨
- ğŸŒŸ **åˆ†äº«**ï¼šå‘Šè¯‰å…¶ä»–äººä½ çš„å®ç°

### æ¨èé˜…è¯»

- [OpenAI Function Calling Guide](https://platform.openai.com/docs/guides/function-calling)
- [ReAct Paper](https://arxiv.org/abs/2210.03629)
- [LangChain Agents](https://python.langchain.com/docs/modules/agents/)
- [å®Œæ•´ç‰ˆ MiniClaw](https://github.com/openclaw/openclaw)

---

**æ­å–œä½ ï¼ğŸ‰**

ä½ å·²ç»æŒæ¡äº†æ„å»º AI Agent çš„æ ¸å¿ƒæŠ€èƒ½ã€‚

ä»è¿™ 400 è¡Œä»£ç å¼€å§‹ï¼Œæ„å»ºå±äºä½ è‡ªå·±çš„ AI åŠ©æ‰‹ï¼
